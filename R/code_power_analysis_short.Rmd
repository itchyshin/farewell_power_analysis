---
title: 'Farewell to Power Analysis\: The Celebrated Kin to the Infamous Statistical
  Significance'
author: "Shinichi Nakagawa, Malgorzata Lagisz, Yefeng Yang & Szymon Drobniak"
date:  "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document:
    toc: yes
    toc_depth: 4
  word_document:
    toc: yes
    toc_depth: 4
  html_document:
    toc: yes
    toc_depth: 4
    number_sections: no
    toc_float:
      collapsed: no
      smooth_scroll: no
    fig.align: center
    fig_caption: yes
    error: no
    warning: no
    message: no
    echo: no
    tidy: yes
    cache: yes
    df_print: paged
    #code_folding: hide
    theme: flatly
always_allow_html: true
editor_options:
  chunk_output_type: console
subtitle: Electronic Supplementary Material
bibliography: references.bib
csl: plos.csl
link-citations: yes
---

```{r}
###########################################################################
# Supplementary Material for Farewell to Power Analysis
# Code written by:
#         Yefeng Yang (yefeng.yang1@unsw.edu.au); School of Biological, 
#                                     Earth and Environmental Sciences, 
#                     University of New South Wales, Sydney, Australia  
#         Shinichi Nakagawa (s.nakagawa@unsw.edu.au); School of Biological, 
#                                     Earth and Environmental Sciences, 
#                     University of New South Wales, Sydney, Australia  
############################################################################        
```

# Setups

```{r setups, echo=FALSE}
# overall Rmarkdown settings
knitr::opts_chunk$set(include = TRUE, message = FALSE,warning = FALSE,
                      tidy.opts = list(width.cutoff = 60),tidy = TRUE, 
                      cache = TRUE, echo=TRUE)
```

Loading packages and custom functions. If your computer do not have the required packages, please install them via `install.packages("package.name")`
```{r installing}
# load required packages
pacman::p_load(dplyr,magrittr, tidyr, stringr, ggplot2, cowplot, patchwork, tidyverse, here, readxl, retrodesign, pwr, Superpower, pander)

# custom function for approximate sample size for main effect and interactive effect
short_cut <- function(d, method = c("normal", "interaction")){
  method <- match.arg(method)
  if(method == "normal"){
    size <- 16*(1/d^2)}
  else{
    size <- 32*(1/d^2)
  }
  size
}
```

# Aims of this Supporting Information

In this document, we show how we got sample sizes presented in the main text in two scenarios under: 1) with relatively large effect sizes (1) and with small but realistic effect sizes (2). In addition, we provide an example of how correlated samples can increase statistical power (3).

# Preambles

Statistical power are determined by the following three parameters: 

(1) Type I error probability, $\alpha$, also known as significance threshold, which is usually fixed at 0.05 (see Table I);

(2) sample size, $n$, that is the number of subjects required for an experiment

(3) standardized effect size, $E[\theta]/\sqrt{Var[\theta]}$, where $\theta$ is the effect size of interest, which is indicated by the real difference between two groups (in our case: obesogenic diet vs. control diet), $E[\theta]$ is the population average/expectation, and $Var[\theta]$ is the respective variance; note that standardized mean difference $d$ is an example of a standardized effect size (for more on effect size, see also Fig 2 and Box 2). 

```{r fig.height= 5}
# drawing Fig 1
### Parameter 1: alpha level vs. power

#### set a range of alpha levels (0.01 to 0.1)
alpha_range <- seq(0.001,1,by=0.01)

#### calculate power at the set alpha levels
#using a medium magnitude of standardized effect size 0.5 
#with a standard deviation of 0.2 
power_range <- retro_design(A = 0.5, s = 0.2, alpha = alpha_range) 

#### create a data frame
power_vs_alpha <- data.frame(alpha = alpha_range, power = power_range$power)

#### plot
power_vs_alpha_plot <- ggplot(power_vs_alpha) + geom_line(aes(x=alpha,y=power),show.legend=F) + 
  scale_y_continuous(breaks = seq(0, 1, 0.2), limits = c(0, 1)) +
  geom_hline(yintercept = 0.8, colour = "red") +
  labs(x="Type 1 error (alpha)", y="Statistical power", 
       title = "(A) alpha level vs. power") + theme_bw()


### Parameter 2: n vs. power

#### set a range of n (2 to 100)
n_range <- seq(2,100,by=2)

## calculate power for a two-sample t test (two-independent-samples-design)
 # using a medium magnitude of standardized effect size 0.5 
power_range2 <- pwr.t.test(d=0.5, n=n_range, sig.level=0.05,
                           type="two.sample", alternative="two.sided")

#### create a dataframe
power_vs_n <- data.frame(n = n_range, power = power_range2$power)

#### plot
power_vs_n_plot <- ggplot(power_vs_n) +
  geom_line(aes(x=n,y=power),show.legend=F) + 
  scale_y_continuous(breaks = seq(0, 1, 0.2), limits = c(0, 1)) +
  geom_hline(yintercept = 0.8, colour = "red") +
  labs(x="Sample size (n)", y="Statistical power", 
       title = "(B) n vs. power") + theme_bw()

### Parameter 3: effect size vs. power

#### create a plausible range of standardized effect sizes
es_range <- seq(0.01,1.01,by=0.01)

#### calculate power with alpha 0.05
power_range3 <- retrodesign::retro_design(A = es_range, s = 0.2, alpha = 0.05)

#### create a dataframe
power_vs_es <- data.frame(es = es_range, 
                          power = power_range3$power, alpha = rep(c("0.05"),length(es_range)))

#### plot
power_vs_es_plot <- ggplot(power_vs_es) + 
  geom_line(aes(x=es,y=power),show.legend=F) + 
  scale_y_continuous(breaks = seq(0, 1, 0.2), limits = c(0, 1)) +
  geom_hline(yintercept = 0.8, colour = "red") +
  labs(x="Effect size (d)", y="Statistical power", 
       title = "(C) effect size vs. power") + 
  theme_bw()


### put all figures together
power_plot <- power_vs_alpha_plot / power_vs_n_plot / power_vs_es_plot 
power_plot
```

### Figure S1
An example showing how the three parameters affect the statistical power: (A) Type I error ($\alpha$), (B) Sample size ($n$), (C) Magnitude of the standardized effect size ($d$). These figures are simulated using `retro_design()` function in `retrodesign` package @gelman2014beyond. See the corresponding code chunk for detailed code.

From Figure S1A we can see that when an experiment commits a higher Type 1 error (which we do not want), it is easier to achieve a desired statistical power (i.e., Cohen's recommendation: 80\% power). Increasing sample size ($n$) and magnitude of standardized effect size are effective ways to increase the statistical power of a given experiment (Figure S1B and S1C). 

# (1) Estimating sample sizes in the 'fictitious' experiment with large effects

When designing an 'fictitious' diet experiment in your grant proposal, You choose a common significance threshold, $\alpha$ = 0.05 and the nominal power level of 80%. Based on your pilot or external information (e.g., relevant studies or a meta-analysis on maternal effect), you assume maternal obesogenic diet will lead to a 30\% increase in males, 20\% in females and 10\% difference between the sexes. To quantify the diet effect using a standardized effect size (i.e., $d$). We assumed the followings:

control group (both male and female) - mean = 100 (arbitrary unit) and standard deviation (sd) = 30;

male treatment group - mean = 130 and sd = 30;

female treatment group - mean = 120 and sd = 30.

Note that we assume the homogeneity of variances among groups (i.e. sd = 30).

```{r}
## scenario 1: large effects

### set up an independent design
design <- ANOVA_design(
  design = "2b*2b", # independent design, which means no correlation
  n =290, # the sample size in each group for testing sex difference
  mu = c(130, 120, 100, 100), 
  sd = 30,
  labelnames = c("diet", "obesogenic ", "control ", "sex", "male", "female"),
  plot = FALSE)

meanplot_largeES <- design$meansplot + labs(x = "Groups", y = "Mean")
Figure_S2 <- meanplot_largeES
Figure_S2
```

### Figure S2 
Visualization of the assumed means and standard deviation (sd) of each group, using the package `Superpower`. Error bars represent sd. Here we assume each group is independent (note that this is not quite true if we take one male and one female from one mother but for convenience, let's assume this)

## Presumed effect sizes (large)

Using these means and sds, we have the following standardized mean difference $d$, corresponding \% differences:

(1) 1.0, corresponding to 30\% increase of memory in males after intervention by diet;

(2) 0.67, corresponding to 20\% increase of memory in females after intervention by diet;

(3) 0.33, corresponding to sex difference or interaction between diet and sex. 

Note that previous experiments suggest usually cognition can more likely to decline but there are cases, offspring cognition of obese mothers could increase so let us keep positive effects for our examples. 

You are planning to use a typical two-sample t-test to examine the statistical significance of the diet effect in males and females. Then you can approximate sample size required for each group using the following formula @lehr1992sixteen: 

$$
n = 16 \frac{Var[\theta]} {E[\theta]^2} = \text{16} \frac{1} {d^2}
$$
However, for the last effect (interaction effect), this requires comparing 4 groups so that this formula does not work. Yet you could still use this formula by replacing 16 with 32 as interaction involves four groups rather than two. 

## Sample size calculation for diet effects

In the following section, we use our custom function (based on the above formula)
and one existing R package `pwr` to estimate the sample size used in your proposed experiment with different scenarios (sample size mentioned in the fictitious story in the main text).

```{r}

# Cohen's d male
(130 - 100)/30

# Cohen's d female
(120 - 100)/30

# the first set (surprising large effects)

## male treatment effect
pwr.t.test(d = 1, sig.level = 0.05, power = 0.8, 
           type = "two.sample", alternative = "two.sided") 
# our result from our custom function is very close
pwr_independent_m_d1 <- short_cut(d = 1, method = "normal")

## female treatment effect
pwr.t.test(d = 0.67, sig.level = 0.05, power = 0.8, 
           type = "two.sample", alternative = "two.sided")
pwr_independent_f_d0.67 <- short_cut(d = 0.67, method = "normal")

```


## Sample size calculation for sex difference (interaction)

We cannot use `pwr.t.test` for getting sample size for the sex difference. So first we can use our formula and then, we use the package `Superpower` to obtain a simulation based sample size. 

```{r}
# Cohen's d sex difference (interaction)
((130 - 100) - (120 - 100))/30

pwr_independent_i_d0.33 <- short_cut(d = 0.33, method = "interaction") 
pwr_independent_i_d0.33
```

Main results of the outputs of the `ANOVA_exact` when detecting large effects:

```{r}
## scenario 1: large effects
### perform ANOVA and calculate power for in dependent design
power_results <- ANOVA_exact(design, alpha_level = 0.05, verbose = FALSE)

power_results$main_results
```


Simulation (using the `ANOVA_exact` function) shows that collecting data from $n$ = `r round(pwr_independent_i_d0.33, 0)` F1 mice (per group)
has `r round(power_results$main_results$power[3],0)`\% power for the interaction or sex difference (see code chunk for R syntax).

We also plot a power curve over a range of sample sizes (Figure S4), from which you can visually explore whether the expected power is achieved for the interaction (bottom panel), and if so, at which sample size.


```{r}
plot.power <- plot_power(design, min_n = 5, max_n = 300, 
                         desired_power = 80, plot = FALSE)

plot.power$plot_ANOVA + labs(x = "Sample size per group")
```

### Figure S3
Power curves for large inter-generational effect in a dependent design (diet and sex are manipulated between animals). Top panel = the main effect - diet; Middle panel = the main effect - sex; Bottom panel = the interactive effect, sex difference. The orange horizontal lines denote the expected statistical power (80\%). Note that the main diet effect is an average effect over the two sexes. 

As you see, the simulation-based method suggests we need 284 subjects to reach 80\% to detect the interaction effect, which confirm what we obtained form the formula was close enough. 


# (2) Estimating sample sizes in the 'ficticious' experiment with realstic (small) effects

This time, we assume maternal obesogenic diet will have more realistic effects on pups' memory: a 5\% increase in males, 3\% in females and thus 1\% difference in the diet effect between the sexes (interaction). 

To calculate $d$, you assume (Figure S8): 

control group (both male and female) - mean = 100 (arbitrary unit) and sd = 30;

male treatment group - mean = 105 and sd = 30;

female treatment group - mean = 103 and sd = 30.

```{r}
## scenario 2: small effects
### set up an independent design
design2 <- ANOVA_design(
  design = "2b*2b", # independent design
  n =7128, # the sample size used for testing sex difference
  mu = c(105, 103, 100, 100), 
  sd = 30,
  labelnames = c("diet", "obesogenic ", "control ", "sex", "male", "female"),
  plot = FALSE)

meanplot_smallES <- design2$meansplot + 
  labs(x = "Groups", y = "Mean", title = "Realistic small effect")
meanplot_smallES
```

### Figure S4
Visualization of the expected means and standard deviation (sd) of each group using the package `Superpower` under more realistic scenarios. Error bars represent sd. Here we assume each group is independent (note that this is not quite true if we take one male and one female from one mother but for convenience, let's assume this).

## Presumed effect sizes (small)

As with the above, we assumed all groups share a common sd = 30 (population standard deviation). Then you can obtain the following standardized mean difference $d$:

(1) 0.16, corresponding to 5\% increase of memory in males after intervention by diet;

(2) 0.1, corresponding to 3\% increase of memory in females after intervention by diet;

(3) 0.06, corresponding to 2\% sex difference or interaction between diet and sex.

## Sample size calculation for diet effects

Following similar procedures in estimating sample sizes for large effects (see above), you can obtain sample sizes with these new presumed effect sizes

```{r}
# Cohen's d male
(105 - 100)/30

# Cohen's d female
(103 - 100)/30

# the first set (realistic small effects)

## male treatment effect
pwr.t.test(d = 0.167, sig.level = 0.05, power = 0.8, 
           type = "two.sample", alternative = "two.sided")
pwr_independent_m_d0.167 <- short_cut(d = 0.167, method = "normal")

## female treatment effect
pwr.t.test(d = 0.1, sig.level = 0.05, power = 0.8, 
           type = "two.sample", alternative = "two.sided")
pwr_independent_f_d0.1 <- short_cut(d = 0.1, method = "normal")

```

## Sample size calculation for sex difference (interaction)

We can also use our formula to estimate (assuming independence of all groups) 

```{r}
# Cohen's d sex difference (interaction)
((105 - 100) - (102 - 100))/30

# sex difference
pwr_independent_i_d0.067 <- short_cut(d = 0.067, method = "interaction")
pwr_independent_i_d0.067
```

We use a similar simulation-based approach to empirically calculate power for the interaction effect using `Superpower`. Main results of the outputs of the `ANOVA_exact` when assuming small effects:

```{r}
## scenario 2: small effects
### perform ANOVA and calculate power for in dependent design
power_results2 <- ANOVA_exact(design2, alpha_level = 0.05, verbose = FALSE)
power_results2$main_results
```

Simulations (using the <code>ANOVA_exact</code> function) show that collecting data from $n$ = `r round(pwr_independent_i_d0.067, 0)` F1 mice (per group)
has `r round(power_results2$main_results$power[3],2)`\% power for the interaction or sex difference. So the simulation result seems to catch with the sample size estimated by the formula. 

# (3) Corrleated samples and statistical power

As mentioned, correlated samples can increase the statistical power of an experiment so that we require fewer samples. Here, we assume that sibling traits are correlated ($r$ = 0.5) regardless of sex. We find $n$ = 3564 can reach the expected statistical power (80\%) for interaction (i.e., sex difference). This number (3567) corresponds to 

```{r}
## scenario 1: small effects
### perform ANOVA and calculate power for in independent design
### assuming the siblings are very similar to each other - r = 0.5
design3 <- ANOVA_design(
  design = "2w*2w", # dependent design 
  n =3564, 
  r = 0.5,
  mu = c(105, 103, 100, 100), 
  sd = 30,
  labelnames = c("diet", "obesogenic", "control", "sex", "male", "female"),
  plot = FALSE)

power_results3 <- ANOVA_exact(design3, alpha_level = 0.05, verbose = FALSE)
power_results3$main_results
```

This number (3567) corresponds to the value calculated from the following formula:

$$
n_{interaction} =  \frac{32} {d^2}(1 - r)
$$

Using this formula, we can assume a lower correlation ($r$ = 0.25) and then, we find $n$ = 5346. As before, we can verify this, using `ANOVA_design`:

```{r}
## scenario 2: small effects
### perform ANOVA and calculate power for in independent design
# assuming the siblings are very similar to each other - r = 0.25
design4 <- ANOVA_design(
  design = "2w*2w",   # dependent design 
  n =5346, 
  r = 0.25,
  mu = c(105, 103, 100, 100), 
  sd = 30,
  labelnames = c("diet", "obesogenic", "control", "sex", "male", "female"),
  plot = FALSE)

power_results4 <- ANOVA_exact(design4, alpha_level = 0.05, verbose = FALSE)
power_results4$main_results
```

As you see, with $n$ = 5346, we have ~80\% power. We note that, as mention in the text, for more complex designs (e.g. including different strains of mice), we cannot use the formula or the functions form `Superpower`. We need to use other software packages which could accommodate such design features. 

# R Session Information

```{r}
sessionInfo() %>% pander()
```

# References


